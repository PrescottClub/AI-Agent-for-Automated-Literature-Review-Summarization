# AI Literature Review Agent Configuration Example
# =====================================================
# Copy this file to .env in the root directory or config/.env
# and fill in your API keys and preferences.

# ===========================================
# Core Application Settings
# ===========================================
LOG_LEVEL=INFO
DEBUG=false

# ===========================================
# LLM Provider Configuration
# ===========================================
# Choose your primary LLM provider: openai, deepseek, ollama, mock
LLM_PROVIDER=deepseek

# LLM API settings
LLM_TIMEOUT_SECONDS=60
LLM_MAX_RETRIES=3
LLM_RATE_LIMIT_DELAY=5.0

# ===========================================
# DeepSeek Configuration (Recommended)
# ===========================================
# Get your API key from: https://platform.deepseek.com/api_keys
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_API_BASE=https://api.deepseek.com/v1

# ===========================================
# OpenAI Configuration (Required for embeddings)
# ===========================================
# Required for embeddings when using DeepSeek as main provider
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_EMBEDDING_MODEL=text-embedding-ada-002
# OPENAI_API_BASE=  # Leave blank for default OpenAI API

# ===========================================
# Ollama Configuration (Local LLM Alternative)
# ===========================================
# Uncomment if using local Ollama server
# OLLAMA_API_BASE=http://localhost:11434/api
# OLLAMA_MODEL=llama3
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# ===========================================
# Academic Data Sources
# ===========================================
# Semantic Scholar API (optional - increases rate limits)
# Get from: https://www.semanticscholar.org/product/api
SEMANTIC_SCHOLAR_API_KEY=your_semantic_scholar_api_key_here
SEMANTIC_SCHOLAR_TIMEOUT_SECONDS=30

# Default sources for literature retrieval
DEFAULT_RETRIEVAL_SOURCES=arxiv,semantic_scholar

# ArXiv settings
ARXIV_MAX_RESULTS=100
ARXIV_API_URL=http://export.arxiv.org/api/
# ARXIV_QUERY_PREFIX=  # Optional prefix for queries

# ===========================================
# Text Processing Configuration
# ===========================================
SPACY_MODEL_NAME=en_core_web_sm
# NLTK_DATA_PATH=  # Leave blank for default

# Embedding model for vector store (sentence-transformers)
SENTENCE_TRANSFORMER_MODEL=all-MiniLM-L6-v2

# ===========================================
# Vector Database Configuration (ChromaDB)
# ===========================================
CHROMA_PERSIST_DIRECTORY=./data/chroma_db
CHROMA_COLLECTION_NAME=literature_collection

# ===========================================
# PDF Processing Settings
# ===========================================
PDF_PROCESSING_TIMEOUT=120
PDF_USER_AGENT=Mozilla/5.0 (compatible; AIResearchAgent/0.1; +http://example.com/bot)

# ===========================================
# Application Directories
# ===========================================
OUTPUT_DIR=./data/outputs
LOG_FILE=./logs/app.log

# ===========================================
# Processing Limits
# ===========================================
MAX_CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_REQUESTS_PER_MINUTE=60
MAX_TOKENS_PER_REQUEST=4000

# ===========================================
# Output Format Configuration
# ===========================================
REPORT_FORMAT=markdown

# ===========================================
# Mock Provider Settings (for testing)
# ===========================================
EMBEDDING_DIMENSION_MOCK=128

# ===========================================
# Docker & Production Configuration
# ===========================================
# Uvicorn server settings
UVICORN_WORKERS=1
UVICORN_HOST=0.0.0.0
UVICORN_PORT=8000

# Redis cache settings
REDIS_URL=redis://localhost:6379
REDIS_MAXMEMORY=256mb
REDIS_MAXMEMORY_POLICY=allkeys-lru

# Monitoring & Security
GRAFANA_ADMIN_PASSWORD=TsearchAdmin2024!
PROMETHEUS_RETENTION_TIME=15d

# Health check settings
HEALTH_CHECK_INTERVAL=30s
HEALTH_CHECK_TIMEOUT=10s
HEALTH_CHECK_RETRIES=3

# ===========================================
# Setup Instructions
# ===========================================
# 1. Copy this file to .env (remove .example from filename)
# 2. Get DeepSeek API key from: https://platform.deepseek.com/api_keys
# 3. Get OpenAI API key from: https://platform.openai.com/api-keys (for embeddings)
# 4. Optionally get Semantic Scholar API key for higher rate limits
# 5. Install spaCy model: python -m spacy download en_core_web_sm
# 6. Run: python -m src.lit_review_agent.cli config-info to verify setup
# 7. For Docker deployment: docker-compose up -d
# 8. For production: docker-compose --profile production up -d