#!/usr/bin/env python3
"""
FastAPI æœåŠ¡å™¨ - ä¸º Vue3 å‰ç«¯æä¾› API æ¥å£
"""

import asyncio
import sys
from contextlib import asynccontextmanager
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import time

from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from pydantic import BaseModel
from datetime import timedelta

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent.parent.parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

try:
    from src.lit_review_agent.agent import LiteratureAgent
    from src.lit_review_agent.utils.config import Config
except ImportError as e:
    print(f"Warning: Could not import modules: {e}")
    LiteratureAgent = None
    Config = None

# å¯¼å…¥è®¤è¯ä¸­é—´ä»¶
try:
    from src.lit_review_agent.middleware.auth import (
        authenticate_user,
        create_access_token,
        users_db,
        ACCESS_TOKEN_EXPIRE_MINUTES,
        Token,
        User as AuthUser,
        get_current_active_user
    )
    print("Auth middleware imported successfully")
except ImportError as e:
    print(f"Warning: Could not import auth middleware: {e}")
    authenticate_user = None
    create_access_token = None
    users_db = None
    ACCESS_TOKEN_EXPIRE_MINUTES = 30
    Token = None
    AuthUser = None
    get_current_active_user = None

# æš‚æ—¶ç¦ç”¨é™æµå™¨
limiter = None

# ä¸´æ—¶ç”¨æˆ·æ¨¡å‹å®šä¹‰


class User(BaseModel):
    username: str
    email: Optional[str] = None
    full_name: Optional[str] = None
    disabled: Optional[bool] = None


class Token(BaseModel):
    access_token: str
    token_type: str

# ä¸´æ—¶ä¾èµ–å‡½æ•°


async def get_current_active_user():
    """ä¸´æ—¶ç”¨æˆ·ä¾èµ–å‡½æ•°"""
    return User(username="demo_user", email="demo@example.com")

# ä¸´æ—¶è£…é¥°å™¨å®šä¹‰ï¼Œç›´åˆ°å®ç°çœŸæ­£çš„é€Ÿç‡é™åˆ¶


def rate_limit_auth(func):
    """ä¸´æ—¶è®¤è¯é€Ÿç‡é™åˆ¶è£…é¥°å™¨"""
    return func


def rate_limit_search(func):
    """ä¸´æ—¶æœç´¢é€Ÿç‡é™åˆ¶è£…é¥°å™¨"""
    return func


def rate_limit_api(func):
    """ä¸´æ—¶APIé€Ÿç‡é™åˆ¶è£…é¥°å™¨"""
    return func


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    print(">> å¯åŠ¨ AI Literature Review API æœåŠ¡å™¨...")
    try:
        agent = get_agent()
        if agent:
            print(">> æ–‡çŒ®ä»£ç†åˆå§‹åŒ–æˆåŠŸ")
        else:
            print(">> æ–‡çŒ®ä»£ç†åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    except Exception as e:
        print(f">> ä»£ç†åˆå§‹åŒ–å¼‚å¸¸: {e}")
        print(">> å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼è¿è¡Œ")

    yield

    # å…³é—­æ—¶æ¸…ç†
    print(">> å…³é—­ AI Literature Review API æœåŠ¡å™¨...")
    global literature_agent
    if literature_agent:
        try:
            # æ¸…ç†èµ„æº
            literature_agent = None
            print(">> èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f">> èµ„æºæ¸…ç†å¼‚å¸¸: {e}")


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="AI Literature Review API",
    description="æ™ºèƒ½æ–‡çŒ®ç»¼è¿°ç³»ç»Ÿ API",
    version="3.1.0",
    lifespan=lifespan,
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "http://localhost:3000",
        "http://127.0.0.1:5173",
        "http://127.0.0.1:3000",
        "file://",
        "*"  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æº
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ·»åŠ å®‰å…¨ä¸­é—´ä»¶
if limiter:
    app.state.limiter = limiter

# OAuth2 scheme for authentication
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/auth/token", auto_error=False)


# è¯·æ±‚æ¨¡å‹
class SearchRequest(BaseModel):
    query: Optional[str] = None  # Legacy structured query field
    rawQuery: Optional[str] = None  # New natural language query field
    sources: List[str] = ["arxiv"]  # Only ArXiv supported
    maxPapers: int = 20
    yearStart: Optional[int] = None
    yearEnd: Optional[int] = None
    retrieveFullText: bool = False
    enableAIAnalysis: bool = True


class QuickSearchRequest(BaseModel):
    query: str = "machine learning"
    maxPapers: int = 3


class ReportRequest(BaseModel):
    papers: List[Dict]
    title: str


# å“åº”æ¨¡å‹
class Paper(BaseModel):
    title: str
    authors: List[str]
    publishedDate: str
    source: str
    summary: str
    keywords: Optional[List[str]] = []
    url: Optional[str] = None
    pdfUrl: Optional[str] = None
    fullTextRetrieved: Optional[bool] = False


class SearchResult(BaseModel):
    papers: List[Paper]
    totalCount: int
    processingTime: float
    summary: Optional[str] = None
    actionPlan: Optional[List[str]] = None


# å…¨å±€å˜é‡
literature_agent = None


def get_agent():
    """è·å–æ–‡çŒ®ä»£ç†å®ä¾‹"""
    global literature_agent
    if literature_agent is None:
        try:
            print(">> æ­£åœ¨åˆå§‹åŒ–å®Œæ•´æ–‡çŒ®ä»£ç†...")
            # å°è¯•åˆå§‹åŒ–å®Œæ•´ä»£ç†
            literature_agent = LiteratureAgent()
            print(">> å®Œæ•´æ–‡çŒ®ä»£ç†åˆå§‹åŒ–æˆåŠŸ")
            return literature_agent
        except Exception as e:
            print(f">> å®Œæ•´ä»£ç†åˆå§‹åŒ–å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆ: {e}")
            # å¦‚æœå®Œæ•´ä»£ç†åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€åˆ°ç®€åŒ–ç‰ˆ
            from src.lit_review_agent.retrieval.arxiv_client import ArxivClient
            # Semantic Scholar removed - using ArXiv only

            # åˆ›å»ºç®€åŒ–çš„ä»£ç†å¯¹è±¡
            class SimpleLiteratureAgent:
                def __init__(self):
                    print(">> åˆå§‹åŒ–ç®€åŒ–ä»£ç†...")
                    self.arxiv_client = ArxivClient(max_results=100)
                    print(">> ç®€åŒ–ä»£ç†åˆå§‹åŒ–å®Œæˆ")

                async def conduct_literature_review(self, **kwargs):
                    """å¿«é€Ÿæœç´¢æ–¹æ³• - ä¸“æ³¨é€Ÿåº¦"""
                    query = kwargs.get('raw_query') or kwargs.get(
                        'research_topic') or kwargs.get('query')
                    max_papers = kwargs.get('max_papers', 20)
                    sources = kwargs.get('sources', ['arxiv'])

                    print(f">> å¿«é€Ÿæœç´¢: {query}")

                    all_papers = []

                    # ä»…ä½¿ç”¨ArXiv
                    if 'arxiv' in sources:
                        try:
                            print(">> å¿«é€Ÿæœç´¢ArXiv...")
                            arxiv_results = await asyncio.wait_for(
                                self.arxiv_client.search(
                                    query=query,
                                    max_results=min(max_papers, 5)  # æœ€å¤š5ç¯‡
                                ),
                                timeout=30  # 30ç§’è¶…æ—¶
                            )
                            all_papers.extend(arxiv_results)
                            print(f">> è·å–åˆ° {len(arxiv_results)} ç¯‡è®ºæ–‡")
                        except Exception as e:
                            print(f">> æœç´¢å¤±è´¥: {e}")
                            # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
                            all_papers = []

                    print(f">> å®Œæˆï¼Œå…± {len(all_papers)} ç¯‡è®ºæ–‡")

                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•è®ºæ–‡ï¼Œè¿”å›è¯´æ˜è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
                    if len(all_papers) == 0:
                        print(">> æœªæ‰¾åˆ°è®ºæ–‡ï¼Œè¿”å›ç©ºç»“æœ")
                        return {
                            'processed_papers': [],
                            'action_plan': [
                                f"ğŸ” æœç´¢æŸ¥è¯¢ï¼š{query}",
                                "âš ï¸ æœªæ‰¾åˆ°åŒ¹é…çš„è®ºæ–‡",
                                "ğŸ’¡ å»ºè®®ï¼šå°è¯•ä¸åŒçš„å…³é”®è¯æˆ–æ‰©å¤§æœç´¢èŒƒå›´",
                                "ğŸŒ æ•°æ®æºï¼šSemantic Scholar"
                            ]
                        }

                    # è½¬æ¢ä¸ºAPIæ ¼å¼
                    processed_papers = []
                    for paper in all_papers:
                        processed_papers.append({
                            'title': paper.title,
                            'authors': paper.authors,
                            'published_date': paper.publication_date.isoformat() if paper.publication_date else '',
                            'source': paper.source,
                            'summary': paper.abstract or '',
                            'keywords': [],
                            'url': paper.url,
                            'pdf_url': paper.pdf_url or '',
                            'full_text_retrieved': False
                        })

                    return {
                        'processed_papers': processed_papers,
                        'action_plan': [
                            f"ğŸ¯ ç¡®å®šç ”ç©¶ä¸»é¢˜ï¼š{query}",
                            "ğŸ“š é€‰æ‹©æ•°æ®æºï¼šarXiv",
                            f"ğŸ” æ‰§è¡Œæ£€ç´¢ç­–ç•¥ï¼šæ£€ç´¢æœ€å¤š{max_papers}ç¯‡ç›¸å…³è®ºæ–‡",
                            "ğŸ“Š åˆ†æè®ºæ–‡å…ƒæ•°æ®ï¼šæ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ç­‰",
                            "ğŸ“ æ•´ç†æœç´¢ç»“æœ"
                        ]
                    }

            literature_agent = SimpleLiteratureAgent()
            print(">> ç®€åŒ–æ–‡çŒ®ä»£ç†åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f">> ä»£ç†åˆå§‹åŒ–å¤±è´¥: {e}")
            print(">> å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼")
            literature_agent = None
    return literature_agent


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "AI Literature Review API",
        "version": "3.1.0",
        "status": "running",
    }


# è®¤è¯ç«¯ç‚¹
@app.post("/auth/token")
async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends()):
    """ç”¨æˆ·ç™»å½•è·å–è®¿é—®token"""
    if not authenticate_user:
        raise HTTPException(
            status_code=status.HTTP_501_NOT_IMPLEMENTED,
            detail="Authentication not available"
        )

    user = authenticate_user(users_db, form_data.username, form_data.password)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user.username},
        expires_delta=access_token_expires
    )
    return {"access_token": access_token, "token_type": "bearer"}


@app.get("/auth/me", response_model=User)
async def read_users_me(current_user: User = Depends(get_current_active_user)):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    return current_user


@app.post("/api/quick-search")
async def quick_search(request: QuickSearchRequest):
    """å¿«é€Ÿæœç´¢ç«¯ç‚¹ - ä½¿ç”¨ArXiv"""
    try:
        print(">> å¿«é€Ÿæœç´¢ç«¯ç‚¹è¢«è°ƒç”¨")

        # å¤„ç†æŸ¥è¯¢å­—ç¬¦ä¸²ç¼–ç é—®é¢˜
        query = request.query.strip()
        max_papers = request.maxPapers

        print(f">> æ¥æ”¶åˆ°æŸ¥è¯¢: {repr(query)}")  # ä½¿ç”¨repræ˜¾ç¤ºåŸå§‹å­—ç¬¦ä¸²

        # æ£€æµ‹å¹¶ä¿®å¤ç¼–ç é—®é¢˜
        if query and ('?' in query or len(query.encode('utf-8', errors='ignore')) != len(query.encode('utf-8'))):
            print(f">> æ£€æµ‹åˆ°ç¼–ç é—®é¢˜ï¼Œå°è¯•ä¿®å¤...")
            # å¦‚æœæŸ¥è¯¢åŒ…å«é—®å·æˆ–ç¼–ç å¼‚å¸¸ï¼Œå¯èƒ½æ˜¯ä¸­æ–‡æŸ¥è¯¢è¢«æŸå
            # æä¾›ä¸€äº›å¸¸è§ä¸­æ–‡æŸ¥è¯¢çš„æ˜ å°„
            chinese_query_mapping = {
                "????": "deep learning",
                "????????": "machine learning",
                "????????????": "artificial intelligence",
                "??????": "neural network",
                "??????????": "computer vision",
                "????????????": "natural language processing"
            }

            if query in chinese_query_mapping:
                original_query = query
                query = chinese_query_mapping[query]
                print(f">> æ˜ å°„æŸåçš„æŸ¥è¯¢: '{original_query}' -> '{query}'")
            elif '?' in query:
                # å¦‚æœåŒ…å«é—®å·ä½†ä¸åœ¨æ˜ å°„ä¸­ï¼Œä½¿ç”¨é»˜è®¤æŸ¥è¯¢
                print(f">> æŸ¥è¯¢åŒ…å«æŸåå­—ç¬¦ï¼Œä½¿ç”¨é»˜è®¤æŸ¥è¯¢")
                query = "machine learning"

        agent = get_agent()
        if agent:
            print(f">> ä½¿ç”¨ArXivæœç´¢: {query}")
            results = await agent.conduct_literature_review(
                raw_query=query,
                max_papers=max_papers,
                sources=['arxiv'],
                retrieve_full_text=False
            )

            processed_papers = results.get('processed_papers', [])
            papers = []
            for paper in processed_papers:
                papers.append({
                    'title': paper.get('title', ''),
                    'authors': paper.get('authors', []),
                    'publishedDate': paper.get('published_date', ''),
                    'source': paper.get('source', 'arxiv'),
                    'summary': paper.get('summary', ''),
                    'url': paper.get('url', '')
                })

            return {
                "papers": papers,
                "totalCount": len(papers),
                "processingTime": 1.0,
                "summary": f"ä»ArXivæ£€ç´¢åˆ°{len(papers)}ç¯‡è®ºæ–‡"
            }
        else:
            # å¦‚æœä»£ç†ä¸å¯ç”¨ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®
            return {
                "papers": [
                    {
                        "title": "Attention Is All You Need",
                        "authors": ["Ashish Vaswani", "Noam Shazeer"],
                        "publishedDate": "2017-06-12",
                        "source": "test",
                        "summary": "The dominant sequence transduction models...",
                        "url": "https://arxiv.org/abs/1706.03762"
                    }
                ],
                "totalCount": 1,
                "processingTime": 0.1,
                "summary": "ä»£ç†ä¸å¯ç”¨ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®"
            }
    except Exception as e:
        print(f">> å¿«é€Ÿæœç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    try:
        agent = get_agent()
        agent_status = "healthy" if agent else "degraded"
        return {
            "status": "ok",
            "timestamp": datetime.now().isoformat(),
            "agent_status": agent_status,
            "version": "3.1.0",
            "services": {
                "api": "running",
                "agent": agent_status,
                "database": "connected" if agent else "unavailable",
            },
        }
    except Exception as e:
        return {
            "status": "error",
            "timestamp": datetime.now().isoformat(),
            "error": str(e),
            "agent_status": "error",
        }


@app.get("/api/status")
async def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    agent = get_agent()
    return {
        "status": "healthy" if agent else "demo",
        "timestamp": datetime.now().isoformat(),
        "agent_initialized": agent is not None,
    }


@app.post("/api/search", response_model=SearchResult)
@rate_limit_search
async def search_literature(
    request: SearchRequest,
    current_user: User = Depends(get_current_active_user)
):
    """æ–‡çŒ®æ£€ç´¢"""
    start_time = time.time()

    try:
        agent = get_agent()

        # Determine which query to use
        query_to_use = request.rawQuery or request.query
        if not query_to_use:
            raise HTTPException(
                status_code=400, detail="Either 'query' or 'rawQuery' must be provided"
            )

        print(f"å¼€å§‹æ£€ç´¢: {query_to_use}")

        if agent:
            # ä½¿ç”¨çœŸå®çš„ä»£ç†ï¼Œæ·»åŠ ä¸¥æ ¼è¶…æ—¶æ§åˆ¶
            print(f">> ä»£ç†å¯ç”¨ï¼Œå¼€å§‹å¿«é€Ÿæœç´¢")
            try:
                if request.rawQuery:
                    # Use natural language processing with timeout
                    results = await asyncio.wait_for(
                        agent.conduct_literature_review(
                            raw_query=request.rawQuery,
                            max_papers=min(request.maxPapers, 5),  # é™åˆ¶æ•°é‡
                            sources=request.sources,
                            retrieve_full_text=False,  # å¼ºåˆ¶å…³é—­å…¨æ–‡æ£€ç´¢
                            year_start=request.yearStart,
                            year_end=request.yearEnd,
                        ),
                        timeout=60  # 60ç§’æ€»è¶…æ—¶ï¼Œç»™AIå’Œå¤–éƒ¨APIè¶³å¤Ÿæ—¶é—´
                    )
                else:
                    # Use legacy structured query with timeout
                    results = await asyncio.wait_for(
                        agent.conduct_literature_review(
                            research_topic=request.query,
                            max_papers=min(request.maxPapers, 5),  # é™åˆ¶æ•°é‡
                            sources=request.sources,
                            retrieve_full_text=False,  # å¼ºåˆ¶å…³é—­å…¨æ–‡æ£€ç´¢
                            year_start=request.yearStart,
                            year_end=request.yearEnd,
                        ),
                        timeout=60  # 60ç§’æ€»è¶…æ—¶ï¼Œç»™AIå’Œå¤–éƒ¨APIè¶³å¤Ÿæ—¶é—´
                    )
            except asyncio.TimeoutError:
                print(">> æœç´¢è¶…æ—¶ï¼Œè¿”å›è¶…æ—¶å“åº”")
                # è¿”å›è¶…æ—¶å“åº”è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
                results = {
                    'processed_papers': [],
                    'action_plan': [
                        f"ğŸ” æœç´¢æŸ¥è¯¢ï¼š{query_to_use}",
                        "â° æœç´¢è¶…æ—¶",
                        "ğŸ”„ è¯·ç¨åé‡è¯•",
                        "ğŸ’¡ å»ºè®®ï¼šä½¿ç”¨æ›´ç®€å•çš„å…³é”®è¯"
                    ]
                }

            print(f">> ä»£ç†è¿”å›ç»“æœ: {type(results)}")
            print(
                f">> ç»“æœé”®: {list(results.keys()) if isinstance(results, dict) else 'Not a dict'}")

            # è½¬æ¢ç»“æœæ ¼å¼
            papers = []
            action_plan = None

            if results and "processed_papers" in results:
                print(
                    f">> æ‰¾åˆ° processed_papersï¼Œæ•°é‡: {len(results['processed_papers'])}")
                for paper_data in results["processed_papers"]:
                    paper = Paper(
                        title=paper_data.get("title", "æœªçŸ¥æ ‡é¢˜"),
                        authors=paper_data.get("authors", []),
                        publishedDate=paper_data.get("published_date", ""),
                        source=paper_data.get("source", "unknown"),
                        summary=paper_data.get(
                            "ai_enhanced_summary", paper_data.get(
                                "summary", "")
                        ),
                        keywords=paper_data.get("keywords", []),
                        url=paper_data.get("url", ""),
                        pdfUrl=paper_data.get("pdf_url", ""),
                        fullTextRetrieved=paper_data.get(
                            "full_text_retrieved", False),
                    )
                    papers.append(paper)

                # Extract action plan from results
                action_plan = results.get("action_plan", [])
            else:
                print(f">> æœªæ‰¾åˆ° processed_papers æˆ–ç»“æœä¸ºç©º")
                print(f">> å®Œæ•´ç»“æœ: {results}")
        else:
            # Agent not available - return error instead of mock data
            raise HTTPException(
                status_code=503,
                detail="Literature agent is not available. Please check system configuration and ensure all required services are running."
            )

        processing_time = time.time() - start_time

        print(f"æ£€ç´¢å®Œæˆ: æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡ï¼Œè€—æ—¶ {processing_time:.2f}s")

        return SearchResult(
            papers=papers,
            totalCount=len(papers),
            processingTime=processing_time,
            summary=f"åŸºäº'{query_to_use}'çš„æ–‡çŒ®æ£€ç´¢å®Œæˆï¼Œå…±æ‰¾åˆ°{len(papers)}ç¯‡ç›¸å…³è®ºæ–‡ã€‚",
            actionPlan=action_plan,
        )

    except Exception as e:
        print(f"æ£€ç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ£€ç´¢å¤±è´¥: {str(e)}")


@app.post("/api/generate-report")
@rate_limit_api
async def generate_report(
    request: ReportRequest,
    current_user: User = Depends(get_current_active_user)
):
    """ç”Ÿæˆç»¼è¿°æŠ¥å‘Š"""
    try:
        print(f"å¼€å§‹ç”ŸæˆæŠ¥å‘Š: {request.title}")

        agent = get_agent()
        if not agent:
            raise HTTPException(
                status_code=503,
                detail="Literature agent is not available for report generation"
            )

        # ä½¿ç”¨çœŸå®çš„agentç”ŸæˆæŠ¥å‘Š
        try:
            # è½¬æ¢paperæ•°æ®æ ¼å¼ä»¥ä¾¿agentå¤„ç†
            papers_data = []
            for paper in request.papers:
                papers_data.append({
                    "title": paper.title,
                    "authors": paper.authors,
                    "published_date": paper.publishedDate,
                    "source": paper.source,
                    "summary": paper.summary,
                    "keywords": paper.keywords,
                    "url": paper.url,
                    "full_text_retrieved": paper.fullTextRetrieved
                })

            # è°ƒç”¨agentçš„æŠ¥å‘Šç”ŸæˆåŠŸèƒ½
            report_result = await agent.generate_comprehensive_report(
                papers_data=papers_data,
                topic=request.title,
                custom_prompt=getattr(request, 'customPrompt', None)
            )

            report = report_result.get('report', '') if isinstance(
                report_result, dict) else str(report_result)

            if not report.strip():
                raise HTTPException(
                    status_code=500,
                    detail="Generated report is empty"
                )

            print("æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return {"report": report}

        except Exception as e:
            print(f"AgentæŠ¥å‘Šç”Ÿæˆå¼‚å¸¸: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"Report generation failed: {str(e)}"
            )

    except Exception as e:
        print(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")


if __name__ == "__main__":
    import uvicorn

    print("å¯åŠ¨ FastAPI æœåŠ¡å™¨...")
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=False, log_level="info")
