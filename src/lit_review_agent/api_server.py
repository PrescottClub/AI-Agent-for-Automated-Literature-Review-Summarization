#!/usr/bin/env python3
"""
FastAPI æœåŠ¡å™¨ - ä¸º Vue3 å‰ç«¯æä¾› API æ¥å£
"""

import asyncio
import sys
from contextlib import asynccontextmanager
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import time

from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import OAuth2PasswordBearer, OAuth2PasswordRequestForm
from pydantic import BaseModel
from datetime import timedelta

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent.parent.parent
if str(current_dir) not in sys.path:
    sys.path.insert(0, str(current_dir))

try:
    from src.lit_review_agent.agent import LiteratureAgent
    from src.lit_review_agent.utils.config import Config
except ImportError as e:
    print(f"Warning: Could not import modules: {e}")
    LiteratureAgent = None
    Config = None

# å¯¼å…¥è®¤è¯ä¸­é—´ä»¶
try:
    from src.lit_review_agent.middleware.auth import (
        authenticate_user,
        create_access_token,
        users_db,
        ACCESS_TOKEN_EXPIRE_MINUTES,
        Token,
        User as AuthUser,
        get_current_active_user
    )
    print("Auth middleware imported successfully")
except ImportError as e:
    print(f"Warning: Could not import auth middleware: {e}")
    authenticate_user = None
    create_access_token = None
    users_db = None
    ACCESS_TOKEN_EXPIRE_MINUTES = 30
    Token = None
    AuthUser = None
    get_current_active_user = None

# æš‚æ—¶ç¦ç”¨é™æµå™¨
limiter = None

# ä¸´æ—¶ç”¨æˆ·æ¨¡å‹å®šä¹‰


class User(BaseModel):
    username: str
    email: Optional[str] = None
    full_name: Optional[str] = None
    disabled: Optional[bool] = None


class Token(BaseModel):
    access_token: str
    token_type: str

# ä¸´æ—¶ä¾èµ–å‡½æ•°


async def get_current_active_user():
    """ä¸´æ—¶ç”¨æˆ·ä¾èµ–å‡½æ•°"""
    return User(username="demo_user", email="demo@example.com")

# ä¸´æ—¶è£…é¥°å™¨å®šä¹‰ï¼Œç›´åˆ°å®ç°çœŸæ­£çš„é€Ÿç‡é™åˆ¶


def rate_limit_auth(func):
    """ä¸´æ—¶è®¤è¯é€Ÿç‡é™åˆ¶è£…é¥°å™¨"""
    return func


def rate_limit_search(func):
    """ä¸´æ—¶æœç´¢é€Ÿç‡é™åˆ¶è£…é¥°å™¨"""
    return func


def rate_limit_api(func):
    """ä¸´æ—¶APIé€Ÿç‡é™åˆ¶è£…é¥°å™¨"""
    return func


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    print(">> å¯åŠ¨ AI Literature Review API æœåŠ¡å™¨...")
    try:
        agent = get_agent()
        if agent:
            print(">> æ–‡çŒ®ä»£ç†åˆå§‹åŒ–æˆåŠŸ")
        else:
            print(">> æ–‡çŒ®ä»£ç†åˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
    except Exception as e:
        print(f">> ä»£ç†åˆå§‹åŒ–å¼‚å¸¸: {e}")
        print(">> å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼è¿è¡Œ")

    yield

    # å…³é—­æ—¶æ¸…ç†
    print(">> å…³é—­ AI Literature Review API æœåŠ¡å™¨...")
    global literature_agent
    if literature_agent:
        try:
            # æ¸…ç†èµ„æº
            literature_agent = None
            print(">> èµ„æºæ¸…ç†å®Œæˆ")
        except Exception as e:
            print(f">> èµ„æºæ¸…ç†å¼‚å¸¸: {e}")


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="AI Literature Review API",
    description="æ™ºèƒ½æ–‡çŒ®ç»¼è¿°ç³»ç»Ÿ API",
    version="3.1.0",
    lifespan=lifespan,
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:5173",
        "http://localhost:3000",
        "http://127.0.0.1:5173",
        "http://127.0.0.1:3000",
        "file://",
        "*"  # å¼€å‘ç¯å¢ƒå…è®¸æ‰€æœ‰æº
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ·»åŠ å®‰å…¨ä¸­é—´ä»¶
if limiter:
    app.state.limiter = limiter

# OAuth2 scheme for authentication
oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/auth/token", auto_error=False)


# è¯·æ±‚æ¨¡å‹
class SearchRequest(BaseModel):
    query: Optional[str] = None  # Legacy structured query field
    rawQuery: Optional[str] = None  # New natural language query field
    sources: List[str] = ["arxiv", "semantic_scholar"]
    maxPapers: int = 20
    yearStart: Optional[int] = None
    yearEnd: Optional[int] = None
    retrieveFullText: bool = False
    enableAIAnalysis: bool = True


class ReportRequest(BaseModel):
    papers: List[Dict]
    title: str


# å“åº”æ¨¡å‹
class Paper(BaseModel):
    title: str
    authors: List[str]
    publishedDate: str
    source: str
    summary: str
    keywords: Optional[List[str]] = []
    url: Optional[str] = None
    pdfUrl: Optional[str] = None
    fullTextRetrieved: Optional[bool] = False


class SearchResult(BaseModel):
    papers: List[Paper]
    totalCount: int
    processingTime: float
    summary: Optional[str] = None
    actionPlan: Optional[List[str]] = None


# å…¨å±€å˜é‡
literature_agent = None


def get_agent():
    """è·å–æ–‡çŒ®ä»£ç†å®ä¾‹"""
    global literature_agent
    if literature_agent is None:
        try:
            print(">> æ­£åœ¨åˆå§‹åŒ–æ–‡çŒ®ä»£ç†...")
            # ä½¿ç”¨ç®€åŒ–çš„é…ç½®æ¥é¿å…é…ç½®è§£æé—®é¢˜
            from src.lit_review_agent.retrieval.arxiv_client import ArxivClient
            from src.lit_review_agent.retrieval.semantic_scholar_client import SemanticScholarClient

            # åˆ›å»ºç®€åŒ–çš„ä»£ç†å¯¹è±¡
            class SimpleLiteratureAgent:
                def __init__(self):
                    self.arxiv_client = ArxivClient(
                        api_url="http://export.arxiv.org/api/",
                        max_results=100
                    )

                    # ç®€åŒ–çš„é…ç½®å¯¹è±¡
                    class SimpleConfig:
                        def __init__(self):
                            self.semantic_scholar_api_key = None
                            self.semantic_scholar_timeout_seconds = 30
                            self.pdf_processing_timeout = 120
                            self.semantic_scholar_api_url = "https://api.semanticscholar.org/graph/v1"

                    self.semantic_scholar_client = SemanticScholarClient(
                        config=SimpleConfig())

                async def conduct_literature_review(self, **kwargs):
                    """ç®€åŒ–çš„æ–‡çŒ®ç»¼è¿°æ–¹æ³•"""
                    query = kwargs.get('raw_query') or kwargs.get(
                        'research_topic') or kwargs.get('query')
                    max_papers = kwargs.get('max_papers', 20)
                    sources = kwargs.get('sources', ['arxiv'])

                    print(f">> å¼€å§‹æœç´¢: {query}")

                    all_papers = []

                    # ä½¿ç”¨arXivæœç´¢
                    if 'arxiv' in sources:
                        try:
                            arxiv_results = await self.arxiv_client.search(
                                query=query,
                                max_results=min(max_papers, 10)
                            )
                            all_papers.extend(arxiv_results)
                            print(f">> ä»arXivè·å–åˆ° {len(arxiv_results)} ç¯‡è®ºæ–‡")
                        except Exception as e:
                            print(f">> arXivæœç´¢å¤±è´¥: {e}")

                    # ä½¿ç”¨Semantic Scholaræœç´¢
                    if 'semantic_scholar' in sources:
                        try:
                            s2_results = await self.semantic_scholar_client.search(
                                query=query,
                                max_results=min(max_papers, 10)
                            )
                            all_papers.extend(s2_results)
                            print(
                                f">> ä»Semantic Scholarè·å–åˆ° {len(s2_results)} ç¯‡è®ºæ–‡")
                        except Exception as e:
                            print(f">> Semantic Scholaræœç´¢å¤±è´¥: {e}")

                    # è½¬æ¢ä¸ºAPIæ ¼å¼
                    processed_papers = []
                    for paper in all_papers:
                        processed_papers.append({
                            'title': paper.title,
                            'authors': paper.authors,
                            'published_date': paper.publication_date.isoformat() if paper.publication_date else '',
                            'source': paper.source,
                            'summary': paper.abstract or '',
                            'keywords': [],
                            'url': paper.url,
                            'pdf_url': paper.pdf_url or '',
                            'full_text_retrieved': False
                        })

                    return {
                        'processed_papers': processed_papers,
                        'action_plan': [
                            f"ğŸ¯ ç¡®å®šç ”ç©¶ä¸»é¢˜ï¼š{query}",
                            "ğŸ“š é€‰æ‹©æ•°æ®æºï¼šarXiv",
                            f"ğŸ” æ‰§è¡Œæ£€ç´¢ç­–ç•¥ï¼šæ£€ç´¢æœ€å¤š{max_papers}ç¯‡ç›¸å…³è®ºæ–‡",
                            "ğŸ“Š åˆ†æè®ºæ–‡å…ƒæ•°æ®ï¼šæ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ç­‰",
                            "ğŸ“ æ•´ç†æœç´¢ç»“æœ"
                        ]
                    }

            literature_agent = SimpleLiteratureAgent()
            print(">> ç®€åŒ–æ–‡çŒ®ä»£ç†åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f">> ä»£ç†åˆå§‹åŒ–å¤±è´¥: {e}")
            print(">> å°†ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æ¨¡å¼")
            literature_agent = None
    return literature_agent


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "AI Literature Review API",
        "version": "3.1.0",
        "status": "running",
    }


# è®¤è¯ç«¯ç‚¹
@app.post("/auth/token")
async def login_for_access_token(form_data: OAuth2PasswordRequestForm = Depends()):
    """ç”¨æˆ·ç™»å½•è·å–è®¿é—®token"""
    if not authenticate_user:
        raise HTTPException(
            status_code=status.HTTP_501_NOT_IMPLEMENTED,
            detail="Authentication not available"
        )

    user = authenticate_user(users_db, form_data.username, form_data.password)
    if not user:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Bearer"},
        )
    access_token_expires = timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    access_token = create_access_token(
        data={"sub": user.username},
        expires_delta=access_token_expires
    )
    return {"access_token": access_token, "token_type": "bearer"}


@app.get("/auth/me", response_model=User)
async def read_users_me(current_user: User = Depends(get_current_active_user)):
    """è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯"""
    return current_user


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    try:
        agent = get_agent()
        agent_status = "healthy" if agent else "degraded"
        return {
            "status": "ok",
            "timestamp": datetime.now().isoformat(),
            "agent_status": agent_status,
            "version": "3.1.0",
            "services": {
                "api": "running",
                "agent": agent_status,
                "database": "connected" if agent else "unavailable",
            },
        }
    except Exception as e:
        return {
            "status": "error",
            "timestamp": datetime.now().isoformat(),
            "error": str(e),
            "agent_status": "error",
        }


@app.get("/api/status")
async def get_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    agent = get_agent()
    return {
        "status": "healthy" if agent else "demo",
        "timestamp": datetime.now().isoformat(),
        "agent_initialized": agent is not None,
    }


@app.post("/api/search", response_model=SearchResult)
@rate_limit_search
async def search_literature(
    request: SearchRequest,
    current_user: User = Depends(get_current_active_user)
):
    """æ–‡çŒ®æ£€ç´¢"""
    start_time = time.time()

    try:
        agent = get_agent()

        # Determine which query to use
        query_to_use = request.rawQuery or request.query
        if not query_to_use:
            raise HTTPException(
                status_code=400, detail="Either 'query' or 'rawQuery' must be provided"
            )

        print(f"å¼€å§‹æ£€ç´¢: {query_to_use}")

        if agent:
            # ä½¿ç”¨çœŸå®çš„ä»£ç†
            if request.rawQuery:
                # Use natural language processing
                results = await agent.conduct_literature_review(
                    raw_query=request.rawQuery,
                    max_papers=request.maxPapers,
                    sources=request.sources,
                    retrieve_full_text=request.retrieveFullText,
                    year_start=request.yearStart,
                    year_end=request.yearEnd,
                )
            else:
                # Use legacy structured query
                results = await agent.conduct_literature_review(
                    research_topic=request.query,
                    max_papers=request.maxPapers,
                    sources=request.sources,
                    retrieve_full_text=request.retrieveFullText,
                    year_start=request.yearStart,
                    year_end=request.yearEnd,
                )

            # è½¬æ¢ç»“æœæ ¼å¼
            papers = []
            action_plan = None

            if results and "processed_papers" in results:
                for paper_data in results["processed_papers"]:
                    paper = Paper(
                        title=paper_data.get("title", "æœªçŸ¥æ ‡é¢˜"),
                        authors=paper_data.get("authors", []),
                        publishedDate=paper_data.get("published_date", ""),
                        source=paper_data.get("source", "unknown"),
                        summary=paper_data.get(
                            "ai_enhanced_summary", paper_data.get(
                                "summary", "")
                        ),
                        keywords=paper_data.get("keywords", []),
                        url=paper_data.get("url", ""),
                        pdfUrl=paper_data.get("pdf_url", ""),
                        fullTextRetrieved=paper_data.get(
                            "full_text_retrieved", False),
                    )
                    papers.append(paper)

                # Extract action plan from results
                action_plan = results.get("action_plan", [])
        else:
            # Agent not available - return error instead of mock data
            raise HTTPException(
                status_code=503,
                detail="Literature agent is not available. Please check system configuration and ensure all required services are running."
            )

        processing_time = time.time() - start_time

        print(f"æ£€ç´¢å®Œæˆ: æ‰¾åˆ° {len(papers)} ç¯‡è®ºæ–‡ï¼Œè€—æ—¶ {processing_time:.2f}s")

        return SearchResult(
            papers=papers,
            totalCount=len(papers),
            processingTime=processing_time,
            summary=f"åŸºäº'{query_to_use}'çš„æ–‡çŒ®æ£€ç´¢å®Œæˆï¼Œå…±æ‰¾åˆ°{len(papers)}ç¯‡ç›¸å…³è®ºæ–‡ã€‚",
            actionPlan=action_plan,
        )

    except Exception as e:
        print(f"æ£€ç´¢å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ£€ç´¢å¤±è´¥: {str(e)}")


@app.post("/api/generate-report")
@rate_limit_api
async def generate_report(
    request: ReportRequest,
    current_user: User = Depends(get_current_active_user)
):
    """ç”Ÿæˆç»¼è¿°æŠ¥å‘Š"""
    try:
        print(f"å¼€å§‹ç”ŸæˆæŠ¥å‘Š: {request.title}")

        agent = get_agent()
        if not agent:
            raise HTTPException(
                status_code=503,
                detail="Literature agent is not available for report generation"
            )

        # ä½¿ç”¨çœŸå®çš„agentç”ŸæˆæŠ¥å‘Š
        try:
            # è½¬æ¢paperæ•°æ®æ ¼å¼ä»¥ä¾¿agentå¤„ç†
            papers_data = []
            for paper in request.papers:
                papers_data.append({
                    "title": paper.title,
                    "authors": paper.authors,
                    "published_date": paper.publishedDate,
                    "source": paper.source,
                    "summary": paper.summary,
                    "keywords": paper.keywords,
                    "url": paper.url,
                    "full_text_retrieved": paper.fullTextRetrieved
                })

            # è°ƒç”¨agentçš„æŠ¥å‘Šç”ŸæˆåŠŸèƒ½
            report_result = await agent.generate_comprehensive_report(
                papers_data=papers_data,
                topic=request.title,
                custom_prompt=getattr(request, 'customPrompt', None)
            )

            report = report_result.get('report', '') if isinstance(
                report_result, dict) else str(report_result)

            if not report.strip():
                raise HTTPException(
                    status_code=500,
                    detail="Generated report is empty"
                )

            print("æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
            return {"report": report}

        except Exception as e:
            print(f"AgentæŠ¥å‘Šç”Ÿæˆå¼‚å¸¸: {e}")
            raise HTTPException(
                status_code=500,
                detail=f"Report generation failed: {str(e)}"
            )

    except Exception as e:
        print(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")


if __name__ == "__main__":
    import uvicorn

    print("å¯åŠ¨ FastAPI æœåŠ¡å™¨...")
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=False, log_level="info")
