# AI Agent for Automated Literature Review & Summarization

Engineered an AI Agent to automate the retrieval, processing, and summarization of domain-specific research papers. This agent extracts key insights and identifies emerging trends from large volumes of textual data.

## Key Features

- Built with Python and LangChain.
- Integrates Large Language Model (LLM) APIs for advanced natural language understanding and generation.
- Utilizes Vector Databases (e.g., FAISS/Chroma) for efficient semantic search.
- Implements Retrieval Augmented Generation (RAG) to improve summary relevance and accuracy.

## Tech Stack

- Python
- LangChain
- OpenAI API (or similar LLMs)
- PyTorch (embeddings)
- Vector Databases (FAISS/Chroma)
- Pandas
- NLTK/spaCy

## Setup

```bash
# Clone the repository
git clone https://github.com/PrescottClub/AI-Agent-for-Automated-Literature-Review-Summarization.git
cd AI-Agent-for-Automated-Literature-Review-Summarization

# Create and activate a virtual environment (recommended)
python -m venv venv
# On Windows:
# .\venv\Scripts\activate
# On macOS/Linux:
# source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Set up your API Keys and LLM Provider
# Create a .env file in the `config/` directory (e.g., `config/.env`)
# Add your API keys and choose your LLM provider. Here are examples for OpenAI and DeepSeek:

# For OpenAI:
# OPENAI_API_KEY="your_openai_api_key_here"
# OPENAI_MODEL="gpt-4-turbo-preview" (Optional, default is gpt-4-turbo-preview)
# OPENAI_API_BASE="your_openai_compatible_api_base_url" (Optional, for custom OpenAI-compatible APIs like local LLMs)
# LLM_PROVIDER="openai" (Set this if OpenAI is your primary provider)

# For DeepSeek (DeepSeek uses an OpenAI-compatible API):
# DEEPSEEK_API_KEY="your_deepseek_api_key_here"
# DEEPSEEK_MODEL="deepseek-chat" (Optional, default is deepseek-chat)
# DEEPSEEK_API_BASE="https://api.deepseek.com" (Optional, default is https://api.deepseek.com)
# LLM_PROVIDER="deepseek" (Set this if DeepSeek is your primary provider)

# You only need to configure the provider you intend to use primarily.
# The `LLM_PROVIDER` variable tells the agent which configuration to use.

# Alternatively, run the interactive setup, which will guide you through these settings:
# python -m src.lit_review_agent.cli setup
```

## Usage

The agent is primarily used via its command-line interface (CLI).

### 1. Conducting a Literature Review

To conduct a literature review on a specific topic, use the `review` command:

```bash
python -m src.lit_review_agent.cli review "Your Research Topic" [options]
```

**Options:**

*   `--max-papers` or `-n`: Maximum number of papers to retrieve (default: 20).
*   `--full-text` or `-f`: Attempt to extract full text from PDFs (default: False).
*   `--output-format`: Output format for the review results (markdown, json, txt; default: markdown).
*   `--output`: File path to save the review results. If not provided, a filename will be auto-generated in the `output/` directory.
*   `--config` or `-c`: Path to a custom configuration file.

**Example:**

```bash
python -m src.lit_review_agent.cli review "AI in drug discovery" --max-papers 10 --output-format json --output data/drug_discovery_review.json
```

This command will search for papers on "AI in drug discovery", retrieve up to 10 papers, and save the results (including summaries, keywords, etc.) in `data/drug_discovery_review.json`.

### 2. Generating a Comprehensive Report

After conducting a review and saving the results (especially in JSON format which contains detailed paper information), you can generate a more comprehensive, structured report using the `generate-report` command:

```bash
python -m src.lit_review_agent.cli generate-report "Your Report Topic" --input path/to/review_results.json --output path/to/your_report.md [options]
```

**Arguments & Options:**

*   `"Your Report Topic"`: The main topic or title for your report.
*   `--input` or `-i` (Required): Path to the JSON file generated by the `review` command. This file contains the list of `LiteratureItem` objects.
*   `--output` or `-o` (Required): File path where the generated report will be saved.
*   `--format` or `-f`: Output format for the report (markdown, html, latex; default: markdown).
*   `--config` or `-c`: Path to a custom configuration file.

**Example:**

```bash
python -m src.lit_review_agent.cli generate-report "AI in Drug Discovery - Q1 2024 Insights" --input data/drug_discovery_review.json --output reports/AI_Drug_Discovery_Report.md --format markdown
```

This command will take the paper data from `data/drug_discovery_review.json`, generate a detailed report on the topic "AI in Drug Discovery - Q1 2024 Insights", and save it as `reports/AI_Drug_Discovery_Report.md` in Markdown format.

### 3. Searching Similar Papers (Vector Search)

If you have already processed and stored papers in the vector database (done automatically during the `review` command), you can search for similar papers based on a query string:

```bash
python -m src.lit_review_agent.cli search "Your search query"
```

### 4. Displaying Agent Statistics

To see statistics about the agent, such as the number of items in the vector store:

```bash
python -m src.lit_review_agent.cli stats
```

### 5. Displaying Configuration

To view the current agent configuration:

```bash
python -m src.lit_review_agent.cli config-info
```

### 6. Interactive Setup

To interactively set up your configuration (e.g., API keys):

```bash
python -m src.lit_review_agent.cli setup
```

## Contributing

Contributions are welcome! Please follow the standard fork-and-pull-request workflow. 